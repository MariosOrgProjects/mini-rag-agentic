# Chunk size in characters (100-2000)
MINI_RAG_CHUNK_SIZE=400

# Overlap between chunks (0-500)
MINI_RAG_CHUNK_OVERLAP=100

# Default corpus directory that holds the 3 pdf documents
MINI_RAG_CORPUS_DIR=corpus

# Embedding backend: "ollama" or "tfidf"
MINI_RAG_EMBEDDING_BACKEND=ollama

# Ollama API base URL, when install ollama locally
MINI_RAG_OLLAMA_BASE_URL=http://localhost:11434

# Ollama embedding model (requires: ollama pull nomic-embed-text)
MINI_RAG_OLLAMA_MODEL=nomic-embed-text

# Ollama request timeout in seconds (5-120)
MINI_RAG_OLLAMA_TIMEOUT=30

# Number of chunks to retrieve (1-20)
MINI_RAG_TOP_K=3

# Minimum similarity score for retrieval (0.0-1.0)
MINI_RAG_SIMILARITY_THRESHOLD=0.0

# Ollama LLM model for text generation (requires: ollama pull llama3.2)
MINI_RAG_LLM_MODEL=llama3.2

# LLM request timeout in seconds (10-300)
MINI_RAG_LLM_TIMEOUT=120

# Maximum tokens for LLM generation (50-2048)
MINI_RAG_MAX_TOKENS=1024

# Directory for log files that holds the application logs
MINI_RAG_LOG_DIR=logs

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
MINI_RAG_LOG_LEVEL=INFO

# Path for vector store persistence
MINI_RAG_VECTORSTORE_PATH=vectorstore
